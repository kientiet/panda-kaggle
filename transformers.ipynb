{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GeForce GTX 1080 Ti', ('10.92', 'gigabytes'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "\n",
    "def format_bytes(size):\n",
    "    # 2**10 = 1024\n",
    "    power = 2**10\n",
    "    n = 0\n",
    "    power_labels = {0 : '', 1: 'kilo', 2: 'mega', 3: 'giga', 4: 'tera'}\n",
    "    while size > power:\n",
    "        size /= power\n",
    "        n += 1\n",
    "    return \"%.2f\" % size, power_labels[n] + 'bytes'\n",
    "\n",
    "torch.cuda.get_device_name(), format_bytes(torch.cuda.get_device_properties(device).total_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.load_dataset import PandaDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Load from data frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/kientiet/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n"
     ]
    }
   ],
   "source": [
    "from trainer.supervised.transformers import TransformersTrainer\n",
    "model = TransformersTrainer()\n",
    "max_epoches = model.get_max_epoches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kientiet/Documents/My Project/python/panda-kaggle/checkpoint/resnet50_32x4d + attention in batch'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = os.path.join(os.getcwd(), \"checkpoint\", model.model_name)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath = checkpoint_path,\n",
    "    save_top_k = 5,\n",
    "    verbose = True,\n",
    "    monitor = 'kappa_score',\n",
    "    mode = 'max'\n",
    ")\n",
    "\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "tb_logger = loggers.TensorBoardLogger('logs/', name = model.model_name)\n",
    "trainer = pl.Trainer(checkpoint_callback = checkpoint_callback,\n",
    "                    nb_sanity_val_steps = 0, \n",
    "                    max_epochs = max_epoches, \n",
    "                    gpus = -1, \n",
    "                    logger = tb_logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "    | Name                                                               | Type                    | Params\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "0   | loss_func                                                          | BCELoss                 | 0     \n",
      "1   | encoder                                                            | ResNetModel             | 11 M  \n",
      "2   | encoder.encoder                                                    | Sequential              | 11 M  \n",
      "3   | encoder.encoder.0                                                  | Conv2d                  | 9 K   \n",
      "4   | encoder.encoder.1                                                  | BatchNorm2d             | 128   \n",
      "5   | encoder.encoder.2                                                  | ReLU                    | 0     \n",
      "6   | encoder.encoder.3                                                  | MaxPool2d               | 0     \n",
      "7   | encoder.encoder.4                                                  | Sequential              | 147 K \n",
      "8   | encoder.encoder.4.0                                                | BasicBlock              | 73 K  \n",
      "9   | encoder.encoder.4.0.conv1                                          | Conv2d                  | 36 K  \n",
      "10  | encoder.encoder.4.0.bn1                                            | BatchNorm2d             | 128   \n",
      "11  | encoder.encoder.4.0.relu                                           | ReLU                    | 0     \n",
      "12  | encoder.encoder.4.0.conv2                                          | Conv2d                  | 36 K  \n",
      "13  | encoder.encoder.4.0.bn2                                            | BatchNorm2d             | 128   \n",
      "14  | encoder.encoder.4.1                                                | BasicBlock              | 73 K  \n",
      "15  | encoder.encoder.4.1.conv1                                          | Conv2d                  | 36 K  \n",
      "16  | encoder.encoder.4.1.bn1                                            | BatchNorm2d             | 128   \n",
      "17  | encoder.encoder.4.1.relu                                           | ReLU                    | 0     \n",
      "18  | encoder.encoder.4.1.conv2                                          | Conv2d                  | 36 K  \n",
      "19  | encoder.encoder.4.1.bn2                                            | BatchNorm2d             | 128   \n",
      "20  | encoder.encoder.5                                                  | Sequential              | 525 K \n",
      "21  | encoder.encoder.5.0                                                | BasicBlock              | 230 K \n",
      "22  | encoder.encoder.5.0.conv1                                          | Conv2d                  | 73 K  \n",
      "23  | encoder.encoder.5.0.bn1                                            | BatchNorm2d             | 256   \n",
      "24  | encoder.encoder.5.0.relu                                           | ReLU                    | 0     \n",
      "25  | encoder.encoder.5.0.conv2                                          | Conv2d                  | 147 K \n",
      "26  | encoder.encoder.5.0.bn2                                            | BatchNorm2d             | 256   \n",
      "27  | encoder.encoder.5.0.downsample                                     | Sequential              | 8 K   \n",
      "28  | encoder.encoder.5.0.downsample.0                                   | Conv2d                  | 8 K   \n",
      "29  | encoder.encoder.5.0.downsample.1                                   | BatchNorm2d             | 256   \n",
      "30  | encoder.encoder.5.1                                                | BasicBlock              | 295 K \n",
      "31  | encoder.encoder.5.1.conv1                                          | Conv2d                  | 147 K \n",
      "32  | encoder.encoder.5.1.bn1                                            | BatchNorm2d             | 256   \n",
      "33  | encoder.encoder.5.1.relu                                           | ReLU                    | 0     \n",
      "34  | encoder.encoder.5.1.conv2                                          | Conv2d                  | 147 K \n",
      "35  | encoder.encoder.5.1.bn2                                            | BatchNorm2d             | 256   \n",
      "36  | encoder.encoder.6                                                  | Sequential              | 2 M   \n",
      "37  | encoder.encoder.6.0                                                | BasicBlock              | 919 K \n",
      "38  | encoder.encoder.6.0.conv1                                          | Conv2d                  | 294 K \n",
      "39  | encoder.encoder.6.0.bn1                                            | BatchNorm2d             | 512   \n",
      "40  | encoder.encoder.6.0.relu                                           | ReLU                    | 0     \n",
      "41  | encoder.encoder.6.0.conv2                                          | Conv2d                  | 589 K \n",
      "42  | encoder.encoder.6.0.bn2                                            | BatchNorm2d             | 512   \n",
      "43  | encoder.encoder.6.0.downsample                                     | Sequential              | 33 K  \n",
      "44  | encoder.encoder.6.0.downsample.0                                   | Conv2d                  | 32 K  \n",
      "45  | encoder.encoder.6.0.downsample.1                                   | BatchNorm2d             | 512   \n",
      "46  | encoder.encoder.6.1                                                | BasicBlock              | 1 M   \n",
      "47  | encoder.encoder.6.1.conv1                                          | Conv2d                  | 589 K \n",
      "48  | encoder.encoder.6.1.bn1                                            | BatchNorm2d             | 512   \n",
      "49  | encoder.encoder.6.1.relu                                           | ReLU                    | 0     \n",
      "50  | encoder.encoder.6.1.conv2                                          | Conv2d                  | 589 K \n",
      "51  | encoder.encoder.6.1.bn2                                            | BatchNorm2d             | 512   \n",
      "52  | encoder.encoder.7                                                  | Sequential              | 8 M   \n",
      "53  | encoder.encoder.7.0                                                | BasicBlock              | 3 M   \n",
      "54  | encoder.encoder.7.0.conv1                                          | Conv2d                  | 1 M   \n",
      "55  | encoder.encoder.7.0.bn1                                            | BatchNorm2d             | 1 K   \n",
      "56  | encoder.encoder.7.0.relu                                           | ReLU                    | 0     \n",
      "57  | encoder.encoder.7.0.conv2                                          | Conv2d                  | 2 M   \n",
      "58  | encoder.encoder.7.0.bn2                                            | BatchNorm2d             | 1 K   \n",
      "59  | encoder.encoder.7.0.downsample                                     | Sequential              | 132 K \n",
      "60  | encoder.encoder.7.0.downsample.0                                   | Conv2d                  | 131 K \n",
      "61  | encoder.encoder.7.0.downsample.1                                   | BatchNorm2d             | 1 K   \n",
      "62  | encoder.encoder.7.1                                                | BasicBlock              | 4 M   \n",
      "63  | encoder.encoder.7.1.conv1                                          | Conv2d                  | 2 M   \n",
      "64  | encoder.encoder.7.1.bn1                                            | BatchNorm2d             | 1 K   \n",
      "65  | encoder.encoder.7.1.relu                                           | ReLU                    | 0     \n",
      "66  | encoder.encoder.7.1.conv2                                          | Conv2d                  | 2 M   \n",
      "67  | encoder.encoder.7.1.bn2                                            | BatchNorm2d             | 1 K   \n",
      "68  | transformers                                                       | TransformerProjectLayer | 13 M  \n",
      "69  | transformers.downsample                                            | Conv2d                  | 262 K \n",
      "70  | transformers.activation                                            | Mish                    | 0     \n",
      "71  | transformers.bn                                                    | BatchNorm2d             | 1 K   \n",
      "72  | transformers.transformers                                          | Transformers            | 12 M  \n",
      "73  | transformers.transformers.position_encoding                        | PositionEmbedding       | 18 K  \n",
      "74  | transformers.transformers.position_encoding.embed                  | Embedding               | 18 K  \n",
      "75  | transformers.transformers.encoder                                  | TransformersBlock       | 12 M  \n",
      "76  | transformers.transformers.encoder.layers                           | ModuleList              | 12 M  \n",
      "77  | transformers.transformers.encoder.layers.0                         | TransformerLayer        | 2 M   \n",
      "78  | transformers.transformers.encoder.layers.0.self_attention          | MultiheadAttention      | 1 M   \n",
      "79  | transformers.transformers.encoder.layers.0.self_attention.out_proj | Linear                  | 262 K \n",
      "80  | transformers.transformers.encoder.layers.0.linear1                 | Linear                  | 525 K \n",
      "81  | transformers.transformers.encoder.layers.0.linear2                 | Linear                  | 524 K \n",
      "82  | transformers.transformers.encoder.layers.0.norm1                   | LayerNorm               | 1 K   \n",
      "83  | transformers.transformers.encoder.layers.0.norm2                   | LayerNorm               | 1 K   \n",
      "84  | transformers.transformers.encoder.layers.0.dropout                 | Dropout                 | 0     \n",
      "85  | transformers.transformers.encoder.layers.0.activation              | ReLU                    | 0     \n",
      "86  | transformers.transformers.encoder.layers.1                         | TransformerLayer        | 2 M   \n",
      "87  | transformers.transformers.encoder.layers.1.self_attention          | MultiheadAttention      | 1 M   \n",
      "88  | transformers.transformers.encoder.layers.1.self_attention.out_proj | Linear                  | 262 K \n",
      "89  | transformers.transformers.encoder.layers.1.linear1                 | Linear                  | 525 K \n",
      "90  | transformers.transformers.encoder.layers.1.linear2                 | Linear                  | 524 K \n",
      "91  | transformers.transformers.encoder.layers.1.norm1                   | LayerNorm               | 1 K   \n",
      "92  | transformers.transformers.encoder.layers.1.norm2                   | LayerNorm               | 1 K   \n",
      "93  | transformers.transformers.encoder.layers.1.dropout                 | Dropout                 | 0     \n",
      "94  | transformers.transformers.encoder.layers.1.activation              | ReLU                    | 0     \n",
      "95  | transformers.transformers.encoder.layers.2                         | TransformerLayer        | 2 M   \n",
      "96  | transformers.transformers.encoder.layers.2.self_attention          | MultiheadAttention      | 1 M   \n",
      "97  | transformers.transformers.encoder.layers.2.self_attention.out_proj | Linear                  | 262 K \n",
      "98  | transformers.transformers.encoder.layers.2.linear1                 | Linear                  | 525 K \n",
      "99  | transformers.transformers.encoder.layers.2.linear2                 | Linear                  | 524 K \n",
      "100 | transformers.transformers.encoder.layers.2.norm1                   | LayerNorm               | 1 K   \n",
      "101 | transformers.transformers.encoder.layers.2.norm2                   | LayerNorm               | 1 K   \n",
      "102 | transformers.transformers.encoder.layers.2.dropout                 | Dropout                 | 0     \n",
      "103 | transformers.transformers.encoder.layers.2.activation              | ReLU                    | 0     \n",
      "104 | transformers.transformers.encoder.layers.3                         | TransformerLayer        | 2 M   \n",
      "105 | transformers.transformers.encoder.layers.3.self_attention          | MultiheadAttention      | 1 M   \n",
      "106 | transformers.transformers.encoder.layers.3.self_attention.out_proj | Linear                  | 262 K \n",
      "107 | transformers.transformers.encoder.layers.3.linear1                 | Linear                  | 525 K \n",
      "108 | transformers.transformers.encoder.layers.3.linear2                 | Linear                  | 524 K \n",
      "109 | transformers.transformers.encoder.layers.3.norm1                   | LayerNorm               | 1 K   \n",
      "110 | transformers.transformers.encoder.layers.3.norm2                   | LayerNorm               | 1 K   \n",
      "111 | transformers.transformers.encoder.layers.3.dropout                 | Dropout                 | 0     \n",
      "112 | transformers.transformers.encoder.layers.3.activation              | ReLU                    | 0     \n",
      "113 | transformers.transformers.encoder.layers.4                         | TransformerLayer        | 2 M   \n",
      "114 | transformers.transformers.encoder.layers.4.self_attention          | MultiheadAttention      | 1 M   \n",
      "115 | transformers.transformers.encoder.layers.4.self_attention.out_proj | Linear                  | 262 K \n",
      "116 | transformers.transformers.encoder.layers.4.linear1                 | Linear                  | 525 K \n",
      "117 | transformers.transformers.encoder.layers.4.linear2                 | Linear                  | 524 K \n",
      "118 | transformers.transformers.encoder.layers.4.norm1                   | LayerNorm               | 1 K   \n",
      "119 | transformers.transformers.encoder.layers.4.norm2                   | LayerNorm               | 1 K   \n",
      "120 | transformers.transformers.encoder.layers.4.dropout                 | Dropout                 | 0     \n",
      "121 | transformers.transformers.encoder.layers.4.activation              | ReLU                    | 0     \n",
      "122 | transformers.transformers.encoder.layers.5                         | TransformerLayer        | 2 M   \n",
      "123 | transformers.transformers.encoder.layers.5.self_attention          | MultiheadAttention      | 1 M   \n",
      "124 | transformers.transformers.encoder.layers.5.self_attention.out_proj | Linear                  | 262 K \n",
      "125 | transformers.transformers.encoder.layers.5.linear1                 | Linear                  | 525 K \n",
      "126 | transformers.transformers.encoder.layers.5.linear2                 | Linear                  | 524 K \n",
      "127 | transformers.transformers.encoder.layers.5.norm1                   | LayerNorm               | 1 K   \n",
      "128 | transformers.transformers.encoder.layers.5.norm2                   | LayerNorm               | 1 K   \n",
      "129 | transformers.transformers.encoder.layers.5.dropout                 | Dropout                 | 0     \n",
      "130 | transformers.transformers.encoder.layers.5.activation              | ReLU                    | 0     \n",
      "131 | transformers.head                                                  | Sequential              | 262 K \n",
      "132 | transformers.head.0                                                | Linear                  | 262 K \n",
      "133 | transformers.head.1                                                | Mish                    | 0     \n",
      "134 | transformers.head.2                                                | BatchNorm1d             | 72    \n",
      "135 | transformers.head.3                                                | Dropout                 | 0     \n",
      "136 | transformers.learned_mean                                          | Sequential              | 513   \n",
      "137 | transformers.learned_mean.0                                        | Linear                  | 513   \n",
      "138 | transformers.learned_mean.1                                        | Flatten                 | 0     \n",
      "139 | transformers.learned_mean.2                                        | Softmax                 | 0     \n",
      "140 | transformers.prob_layer                                            | Linear                  | 2 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e80539479b454dbc0ee9feee0ce26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', max=200.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder = trainer.lr_find(model, min_lr = 1e-8, max_lr = 5., num_training = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3yV5f3/8dfnZBKSEIQkQMImyB4SkSGK4sAFuMG66qDWYlur9qdtv85aba21Wql1tm6ruHDiVkRQwt4rrDBDwgiE7Ov3xznSiAEOIefcSc77+Xich9z3ue6Tz7lKeee6x3WZcw4REZFg+LwuQEREGg6FhoiIBE2hISIiQVNoiIhI0BQaIiISNIWGiIgELdrrAupKy5YtXYcOHbwuQ0SkQZk1a9Y251xqsO0bTWh06NCBnJwcr8sQEWlQzGzt4bTX6SkREQmaQkNERIKm0BARkaApNEREJGgKDRERCZpCQ0REgqbQCLHCPWUAOOeYt37Hvm0RkYao0TynUV/sLq3g1ZnrOf+YTN6et4Hb317E5YPbs7u0gjdmb8AMxvTL4MEL++LzmdfliogcFoXGAVRVOU568At+fmJnxg5sF/RxT09dzUOfLOfpr1ezeVcJ7Vsk8Nx0/7Mz153YmeKyCp6bvpaebZK5ZlinUJUvIhISCo0D2LSrhLUFxXy9cluNobG1qIS35mzgqqEdiY7yn+Urq6jihW/X0isjma27SslKS2TSz4cwbeU2qqocZ/RujXOOLbtK+POHSzk+qyXdWiWH+6uJiNSaQuMA1m7bA8CyzUX79jnn2Lm3nJSEWJ74Mpenvl5NSXkV5/bP4J35GymvcOQXlfKXC/owqGMLzCA+JorTe7ba9xlmxv3n9WHonz/j6amreeDCvmH/biIitaXQOIA1BcUArN62h9KKSuKio/jT+0t4bvpa3rnheN6et5Eon/HIpyt4+uvV7NxbDkDHlk05MSv1oNcrmjeNZXS/DN6ck8cfzupBs4SYsHwnEZEjpbunDmBtgX+kUVHlyM3fwxfLtvLk1NWUVlRx7XM55BeVcu+YXqQnx9MqOZ53bziev5zfh79f3C+oC9yXDmpHSXkVk2bnhfqriIjUGY00DmBtQTGx0T7KKqpYuGEnf/1oGUenJzGiexr//GIVSfHRjOmfweh+GcRG+4jyGb0ymgX9+T3bNKN/uxSenprLef0zaN40NoTfRkSkbmiksZ+iknKcc6wp2MNxHY8iJsp47ItVbNlVym1nduMXJ3WhVXI85x+TSXxMFE1io4iq5a2zd5zTk227y5jw8mwqKqvq+JuIiNQ9hUY1xWUVDLn/M57+ejVrC4rJSkuiU8tEcrftoe1RTTghK5WmcdF8etOJ/OGs7kf88/q1TeGP5/Zi2soC/vHZyjr4Bg3XuoJivltdSFWVO+xjN+zYy33vL+GaZ2cyed7GEFQnIt/T6alqlm/ZTVFJBY99sYq95ZV0aJnAtt1JLNtSxCUD2++7VtE0ru667aLstnyzchsTP1/JqT3SD+sUV0NXXlnFtt2lfJtbyK1vzKekvIr2LRJ4dNwx9M5sRkVlFVE+w+zHI7lvcwuYtqqAUX1bc82zOWzcUULzpjF8unQrZRVVXDAg04NvJNL4KTSqWbppFwAFgak+2rdoinPw6ZItXJgdun+E7hrVi+m5Bfz6v3N56xdDSawWSq/PymPmmkJuP6cHCbF1+z/X+ws2sXHHXq4Y0oGYqPANOtcXFvPvaWt4c04e24v9d50NaN+ccQPb8bePlnHtczlcPqQ9D3+ygtSkOM7q05obTs4iMS6aisoqnvp6NQ9MWUZlleORT1cQF+3j5fGD/A9MPpvDbyfNo2ViLMOPTgvbdxKJFObc4Z8OqI+ys7PdkS73eufkRfx35nqifUZRaQVf3jKczOYJ7NpbHvIL1dNWbuPyZ77j5G5pPH7pALYXl/HXj5bx8nfrARjcqQVPXZFd4ygnv6iUqSvyGdW3zb4HDQ+ktKKStYFTQf/39kKcg94ZzXjwor50TU8KyXcD/zMuXy7P57VZeXy4cDM+g9N6tGJIlxY0T4hlRPc04qKjWLxxF+c/9g17yys5vktL4mN8fLp0K22aNWFw5xbMWbedVfl7OKNXK647sTPPz1jLWX1ac1IgIIrLKjjvn9+wYcdeHh7bj14ZzUhLigegssrV+vqTSGNlZrOcc9lBtw9laJjZSOBhIAp4yjl3/37vPwScFNhMANKccynV3k8GFgNvOecmHOxn1UVojHtiBsXllfTOSOaN2RuYd8dpYf0N/JmvV3P3u4tJio+motJRUlHJ+BM60TUtiZsnzSM5PoaTjk6ltKKKlIQYOrZsSoumcTwwZRmbd5UwLKslj15yDM2a/O+5j7KKKh75dAUtEmO5dFB7xkycxqKN/hHVsKyWXDAgk7veWczukgpuOq0r1wzr9KN/WCurHJNmradnm2a1On3mnOPudxfz72lrSEmI4fxjMrl2WCdaNYuvsf2M3AJW5e9m3LHt8PmMWWsLue/9pWzcsZfmTWP51YgsTu2RXuNpK/CPZMZMnLZvxNivbQol5ZWsKdjD81cfx7Edjjrs7yDSWNWb0DCzKGA5cCqQB8wExjnnFh+g/Q1Af+fcVdX2PQykAoWhDg3nHAP++Amndk/njlE92LhjL13SQveb94FqeG/BJqavKqDKwdXHd9hXw6y1hTwzbQ2z1mwnMT6a7XvK9v2jmNm8CRdnt+XhT1fQrEkMlw5qT0JsFHvKKvlqeT5z1+8AYPjRqXyxLJ9bTj+azOZNOL1nK+JjosgvKuUPby1gyqItDGjfnIfH9iOzeQLllVWsLyzmnncX8/myfADOOyaDv17ww8kWt+8p47s1hfRonUxm8yZsLy7n2W/WsK6wGOcchcXlfLU8nyuHdOB3Z3YnNjr0QbyzuJyFG3cyd/0OPlq0mfiYKDbu3EtJeRXv3XA8zRJieH76Wsoqq7hkYDtSEnTLs0Sm+hQag4E7nXOnB7ZvA3DO3XeA9t8AdzjnPg5sDwBuAT4EskMdGluLShh476fcfnYPrjq+Y60/J5x2FJexrrCYTqmJJMZFM2/9Dv760TKmrti2r03LxDh+f1Y3npu+ljnrdnBWn9ZMvOSYH32Wc463527k/95eSJOYKM47JpMXZ6ylqLSCaJ/x+7O6s75wL89MW83DY/vRrVUyb87ZQPOEGJ76ejX5RaUAxMf4qHL+i9yZzZtgGGYwslcrbh3Z7YCjg3BYunkXYyZOw2dGSpMYNu4sASAhNoqz+7SmS1oi+UWlnD8gU3OCScQ43NAI5YXwDGB9te084LiaGppZe6Aj8Flg2wc8CFwKnBLCGvf5fo6pbq3DO7o4EikJsT/4Dblv2xSev/o4dhSXERPlo0lM1L4RwZDOLXnyq1yuG965xs8yM8b0z6BHm2SufOY7/vXlKk7rkc6pPdLp3y6FLmlJVFU5vl1dwH3vL6W0onLfReyj05P4y/l9yNtezLrCYiqqHD85rl3YR2qH0q1VMv8dP5jXZ+exKn83957bm9Yp8Tw9dTXvzd/EnrJKon3GM9PWcM3xHfnNaV2Ji47yumyReqW+3D01FpjknKsMbF8PvO+cyzvYb6ZmNh4YD9CuXfDTl9dk6aZAaDSC3zBrOtWSnhzPH87ucchju6Yn8e4vh7G1qORHfeELjDguefJbUpPi+Pzm4cTH+EhNjDvkBfj6om/bFPq2TfnBvgcu7Ms9Y3pRWl5FlXP8ZcpSHv8ql2mrtvHU5cce8NpLUUk5q7ftIS0pnvTkOE9HUSLhEsrQ2AC0rbadGdhXk7HAL6ptDwaGmdn1QCIQa2a7nXO3Vj/IOfcE8AT4T08dSbFLNxeRmhTHUZrOg6Oaxh6wH4Z0bsk/xvWnd0YzOrRsGubKQic+Jor4GP+o4r7z+nDS0Wnc+N+5XPtcDq9dN3jfezuKy/jDWwuZvXb7vtNbAIlx0cTH+Gie4O87MxjRLZ1LjmvHN6sK6Ngyod6NvERqI5TXNKLxXwgfgT8sZgKXOOcW7deuG/7rFh1dDcWY2ZWE4ZrG2f+YSvOEWJ6/usYzaBKBPlm8hWufz2FEtzT+ckFfKqscP/3PdyzfvJsze7ciKz2JzqlN2bTTv/ZKaUUVhXtK2V5cTnFZBQs37CLKZ1RWOaJ9xrUndOLc/hl8tnQrHy7czO3n9OCYds29/poS4erNNQ3nXIWZTQCm4L/l9hnn3CIzuxvIcc5NDjQdC7xSU2CES2WVY8WW3Vw2qL1XJUg9dEqPdO48pyf3vLuYYX/+jL3llUT7fDx++YB9z4UczEeLNvPVinyGd03j/QWbeOyLVTz2xSoAkuKjGfvEDG4+rSvn9s8kNSku1F9HpE7o4T5gVf5uRjz4JQ9c0IcLs9se+gCJKMs2F/HEV7lkNG/C2X1a1/ohyPWFxUxdsY0OLRPo1iqZX748h69XbiPaZ1wwIJNfnNSFtkcl1HH1IgdXb0YaDcn3d051b93wL4JL3Tu6VRIPXnTkKyy2PSqBS4773w0bL1xzHMu3FPHCjLW88t16Js3K44IBmfy/kd00Vb7UWw3jlpcQW7q5CJ9Bl7REr0uRCNM1PYm7R/fiy98O5yfHteP12Xmc9chUZq/b7nVpIjXSSAP/RIUdWjbdd4eMSLi1btaEu0b34vwBmfzipdlc9K/pXD2sI9NXFbB44y6axEQRHxvFiV1TeeCCPrq9VzyjkQawbEsR3VrpdkjxXp/MFN69YRgjuqfx+Je5bC8u4+rjO3JBdib926YwaVYeb8/VmiHinYgfaRSXVbCusJjz+mv9BakfmjWJ4V+XDmB+3k56tEneN2lmVZXj3H9O4973l3By9zSS42MO8UkidS/iRxol5VVcNqg9gzu38LoUkX3MjL5tU34wy7LPZ9w9uhcFu0v5xYuzKa2oPMgniIRGxIfGUU1juXt0LwZ21HTZUv/1bZvC/ef3YeqKbUx4aQ7lWltewiziQ0Okobkouy13j+7Jx4u38JtX51FZi3XVRWor4q9piDRElw/uQHFZJfd/sJQ9pRU8dFE/miXoGoeEnkYaIg3UdSd25p7RPZm6Ip8zH5nKZ0u3UFnlaCyzPEj9pJGGSAN22eAO9Mpoxi2T5nPVf/zT6GSkNOHxywbUamlekUPR3FMijUBZRRVvzM5ja1Ep/525nh3FZdx6RjfOH5BJQqx+N5QDqzfLvYabQkPEb8uuEn7x4mxy1m4nLSmO138+RBMhygEdbmjomoZII5OeHM9r1w3mlfGD2Fteyc+en8WkWXk88ukKKnSLrhwhjVtFGiEzY1CnFjwytj9XPTuTm1+bB0CVc/z6lK4eVycNmUJDpBE7qVsaL187iPiYKP4zbTX/+Gwlw7JSGdBeKwZK7ej0lEgjN6hTC/q1TeHuMb1o3SyeCS/NZtvuUq/LkgZKoSESIZLj/RMhFu4pY8JLsymr0PUNOXwKDZEI0iujGfef35sZuYXc8PJszV0lh02hIRJhzu2fyR3n9GDKoi3c9sYCPUEuh0UXwkUi0E+HdmR7cTmPfLqCXm2SuXJoR69LkgZCoSESoX49Ioslm3Zxz3tLSIiN5qJj23pdkjQAOj0lEqF8PuOhi/sxpHMLfvv6fCZ+vtLrkqQBUGiIRLDEuGieufJYzu7Tmr99vJwFeTu9LknqOYWGSISLifJx77m9adE0llsmzdMysnJQIQ0NMxtpZsvMbKWZ3VrD+w+Z2dzAa7mZ7Qjs72dm081skZnNN7OLQ1mnSKRr1iSGP53bm6Wbi7hJqwHKQYQsNMwsCpgInAH0AMaZWY/qbZxzNzrn+jnn+gH/AN4IvFUMXO6c6wmMBP5uZimhqlVE4JQe6dx2Rjfenb+JP3+41OtypJ4K5UhjILDSOZfrnCsDXgFGH6T9OOBlAOfccufcisCfNwJbgdQQ1ioiwPgTOnHJce14cmous9dt97ocqYdCGRoZwPpq23mBfT9iZu2BjsBnNbw3EIgFVtXw3ngzyzGznPz8/DopWiSSmRm/O7M7rZLjue31BZpqRH6kvlwIHwtMcs794AqcmbUGngd+6pz70d9e59wTzrls51x2aqoGIiJ1ITEumj+O6cWyLUXc+vp8qnR9Q6oJZWhsAKo/LZQZ2FeTsQROTX3PzJKB94DfO+dmhKRCEanRiO7p3HRqV96Ys4H7PljidTlSj4TyifCZQJaZdcQfFmOBS/ZvZGbdgObA9Gr7YoE3geecc5NCWKOIHMCEk7uwbXcpT05dTWpSHONP6Ox1SVIPhGyk4ZyrACYAU4AlwKvOuUVmdreZjarWdCzwivvhrGkXAScAV1a7JbdfqGoVkR8zM+44pydn9WnNn95fyudLt3pdktQD1lhmuMzOznY5OTlelyHS6JRWVHLWI19TWlHJxzeeSHxMlNclSR0ys1nOuexg29eXC+EiUk/FRUdxz+herC/cy69emcNjX6xiV0m512WJRxQaInJIgzu34KdDO/DR4i38+cOl/PPzH90BLxFCoSEiQbnjnJ7k/ulMzurdmhdmrGXnXo02IpFCQ0SCZmb8fHhndpdW8MKMtV6XIx5QaIjIYemV0YwTu6byj89W8NGizV6XI2Gm0BCRw/bXC/tydHoSP3thFv+ettrrciSMFBoicthSk+J4ZfxgTumezl3vLObudxZrOvUIodAQkVppEhvFvy4dwJVDOvDMtNX8/IVZ7C3TAk6NnUJDRGotymfcOaont5/dg4+XbOGWSfNoLA8MS81COfeUiESIq47vSElFJX/5cBkD2jfnp0M7el2ShIhCQ0TqxHUndGb22h3c8+5i4mOiGDewndclSQjo9JSI1Amfz/jHuP6c0DWV295YwPN6jqNRUmiISJ1pEhvFk5dnM6JbGndOXsTXK7Z5XZLUMYWGiNSpmCgfD4/rT5fURK76z0wmvDSb9YXFXpcldUShISJ1LjEumuevHsglx7Xj86VbuelV3VXVWCg0RCQk0pLjuXNUT247szvfrSnkkyVaxKkxUGiISEiNPbYtnVKbcv8HS/TUeCOg0BCRkIqO8nHjKV1Zlb+Hr5bne12OHCGFhoiE3MherUhNitN06o2AQkNEQi4mysfF2W35bNlW8rbrTqqGTKEhImEx7rh2GPDit+u8LkWOgEJDRMIiI6UJZ/ZuzXPfrKFwT5nX5UgtKTREJGx+fUoWxeWVPPFVrtelSC0pNEQkbLqkJTGqbxue/WYNawv2eF2O1IJCQ0TC6pbTjyY22sd1L8ympFyLNjU0IQ0NMxtpZsvMbKWZ3VrD+w+Z2dzAa7mZ7aj23hVmtiLwuiKUdYpI+GQ2T+DvF/djyaZd3P72Qq/LkcMUsvU0zCwKmAicCuQBM81ssnNu8fdtnHM3Vmt/A9A/8OejgDuAbMABswLHbg9VvSISPid1S2PCSV149POVDGjfnIuP1dobDUUoRxoDgZXOuVznXBnwCjD6IO3HAS8H/nw68LFzrjAQFB8DI0NYq4iE2Y2ndmVolxb8v9cXkPX793nwo2VelyRBCGVoZADrq23nBfb9iJm1BzoCnx3OsWY23sxyzCwnP1/TE4g0JFE+45+XDOB3Z3ajX9sUnv56NbtKyr0uSw6hvlwIHwtMcs4d1lUx59wTzrls51x2ampqiEoTkVBplhDD+BM6c/vZPSkuq+SNWXlelySHEMrQ2AC0rbadGdhXk7H879TU4R4rIg1c78xm9GubwnPT11JeWeV1OXIQoQyNmUCWmXU0s1j8wTB5/0Zm1g1oDkyvtnsKcJqZNTez5sBpgX0i0khdfXxHcrft4dS/fcnUFTrdXF+FLDSccxXABPz/2C8BXnXOLTKzu81sVLWmY4FXXLVlvZxzhcA9+INnJnB3YJ+INFJn92nNU5dn4/MZ1z0/i9z83V6XJDWwxrIEY3Z2tsvJyfG6DBE5Qht37OWsR6bSqlkT3rx+CPExUV6X1KiZ2SznXHaw7evLhXAREQDapDThwYv6smTTLp6aqjmq6huFhojUOyd3S+eMXq2Y+PkqNu7Y63U5Uk1QoWFmTc3MF/hzVzMbZWYxoS1NRCLZ787sTpVz3PTqPHbu1fMb9UWwI42vgHgzywA+Ai4D/hOqokRE2h6VwB/H9GLmmkLGTJxGwe5Sr0sSgg8Nc84VA+cB/3TOXQj0DF1ZIiJwYXZbnrtqIKu37eHtuRu9Lkc4jNAws8HAT4D3Avt0S4OIhNyQLi05Oj2JDxdt9roUIfjQ+DVwG/Bm4FmLTsDnoStLROR/Tu+ZTs6aQp2iqgeCCg3n3JfOuVHOuT8HLohvc879MsS1iYgAcFrPVlQ5+GTJFq9LiXjB3j31kpklm1lTYCGw2MxuCW1pIiJ+Pdskk5HShLfmbKSxPJDcUAV7eqqHc24XMAb4AP805peFrCoRkWrMjJ8O7cD03AKm6NqGp4INjZjAcxljgMnOuXL8K+qJiITFFUM60L11MndOXkyR1t3wTLCh8TiwBmgKfBVYNGlXqIoSEdlfTJSPP53bi827SnjyK00v4pVgL4Q/4pzLcM6d6fzWAieFuDYRkR/o3645Z/VpzVNfrya/SHdSeSHYC+HNzOxv3y+tamYP4h91iIiE1U2ndqW0ooqJn6/0upSIFOzpqWeAIuCiwGsX8O9QFSUiciCdUhMZ0y+D13LWs7fssFaIljoQbGh0ds7d4ZzLDbzuAjqFsjARkQM5f0AGe8oq9dyGB4INjb1mdvz3G2Y2FNB8xSLiiUEdW9AqOZ63527wupSIEx1ku+uA58ysWWB7O3BFaEoSETk4n88Y1a8Nz3y9msI9ZRzVNNbrkiJGsHdPzXPO9QX6AH2cc/2Bk0NamYjIQZzbP4OKKsdtb8ynvLLK63IixmGt3Oec2xV4MhzgNyGoR0QkKN1bJ3P72T2YsmgLt72xwOtyIsaRLPdqdVaFiEgtXHV8R64d1pFJs/JYs22P1+VEhCMJDU0jIiKeu2ZYJ6J9xovfrvW6lIhw0NAwsyIz21XDqwhoE6YaRUQOKD05ntN7tuLVnDw9txEGBw0N51yScy65hleScy7YO69ERELqssHt2bm3nDfn6BbcUDuS01OHZGYjzWyZma00s1sP0OYiM1tsZovM7KVq+/8S2LfEzB4xM11DEZEaHdfxKPpkNuNfX66iQndShVTIQsPMooCJwBlAD2CcmfXYr00W/mVkhzrneuJfVhYzGwIMxX+Lby/gWODEUNUqIg2bmTHhpC6sKyxm8ryNXpfTqIVypDEQWBmYdqQMeAUYvV+ba4GJzrntAM65rYH9DogHYoE4IAbQfAEickCndE+nW6sk/v7JCnYUl3ldTqMVytDIANZX284L7KuuK9DVzKaZ2QwzGwngnJsOfA5sCrymOOeWhLBWEWngfD7j7tG92LyzhGuezaGkXBfFQyGk1zSCEA1kAcOBccCTZpZiZl2A7kAm/qA52cyG7X+wmY3/frr2/Pz8MJYtIvXRwI5H8beL+zJr3Xbu/2Cp1+U0SqEMjQ1A22rbmYF91eURWD7WObcaWI4/RM4FZjjndjvnduNfl3zw/j/AOfeEcy7bOZedmpoaki8hIg3L2X3acNmg9jw7fQ1z1m33upxGJ5ShMRPIMrOOZhYLjAUm79fmLfyjDMysJf7TVbnAOuBEM4sOrE1+IqDTUyISlFtOP5r0pHhufm0eW3eVeF1OoxKy0HDOVQATgCn4/8F/1Tm3yMzuNrNRgWZTgAIzW4z/GsYtzrkCYBKwClgAzAPmOefeCVWtItK4JMXH8NDF/di0s4Rz//kNq/J3e11So2HONY7ZQLKzs11OTo7XZYhIPbJww06ueOY7kpvE8PaEoSTHx3hdUr1jZrOcc9nBtvf6QriISMj0ymjGY5cOYH1hMb/571wayy/JXlJoiEijNrDjUdx6Rjc+WbKVDxZu9rqcBk+hISKN3k+HdqRbqyTufW+Jnt84QgoNEWn0onzGHef0ZMOOvfznmzVel9OgKTREJCIM7tyCoV1a8Nw3azSp4RFQaIhIxLhicAc27izh48Wayq62FBoiEjFGdE8ns3kTnp2+xutSGiyFhohEjCifcdmg9szILWTp5l1el9MgKTREJKJclN2WuGgfz36jNcVrQ6EhIhGledNYxvTL4K05G9hZXO51OQ2OQkNEIs7lQ9qzt7ySl2eu87qUBkehISIRp2ebZpzQNZWJn6+kYHep1+U0KAoNEYlIt5/dnZZb8lh+weWQnAw+n/+/118Pq1Z5XV69pVluRSQyffABZeeeB+XlxFZVm1okJsb/mjQJzjjDu/rCRLPciogcyqpVcMEFxJaW/DAwAMrLobgYLrhAI44aKDREJPI8+KA/HA6mvBweeig89TQgCg0RiTwvvBBcaDz/fHjqaUAUGiISeXYHufxrsO0iiEJDRCJPYmLdtosgCg0RiTyXXuq/Q+pgYmLgssvCU08DotAQkchz003BhcaNN4anngZEoSEikadzZ/9zGAkJPwoPFxPj3z9pkr+d/IBCQ0Qi0xlnwPz5MH48JCfjzCiKTWDTRZf590fAg321odAQkcjVuTM8+ijs3ElpaTnn/PFdxvW9lL1tO3hdWb2l0BARAeJjorjvvD6sLSjmnvcW01imWKprIQ0NMxtpZsvMbKWZ3XqANheZ2WIzW2RmL1Xb387MPjKzJYH3O4SyVhGRwZ1b8LMTO/HSt+u4/8OlCo4aRIfqg80sCpgInArkATPNbLJzbnG1NlnAbcBQ59x2M0ur9hHPAfc65z42s0SgKlS1ioh879aR3dhTWsHjX+ayp7SCu0b1IspnXpdVb4QsNICBwErnXC6Amb0CjAYWV2tzLTDRObcdwDm3NdC2BxDtnPs4sF+PZYpIWJgZd4/qRdO4aB7/MpfiskoevLAvZgoOCO3pqQxgfbXtvMC+6roCXc1smpnNMLOR1fbvMLM3zGyOmT0QGLn8gJmNN7McM8vJz88PyZcQkcjj8xm3ndGdX57chTdmb+DNORu8Lqne8PpCeDSQBQwHxgFPmllKYP8w4GbgWKATcOX+BzvnnnDOZTvnslNTU8NVs4hEiF+d0pWBHY7i/95ayJZdJV6XUy+EMjQ2AG2rbWcG9lWXB0x2zpU751YDy/GHSB4w16BZ/msAAAxsSURBVDmX65yrAN4CjglhrSIiPxLlM+47vzd7yip5e65GGxDa0JgJZJlZRzOLBcYCk/dr8xb+UQZm1hL/aancwLEpZvb98OFkfngtREQkLDqnJtI7oxnvzt/kdSn1QshCIzBCmABMAZYArzrnFpnZ3WY2KtBsClBgZouBz4FbnHMFzrlK/KemPjWzBYABT4aqVhGRgzm7T2vm5+1kbcEer0vxnNYIFxE5hLztxRz/58+56dSu3DAiy+ty6tThrhEeyltuRUQahczmCQzu1IK/fbKcFVt30ysjmeFHp9E1Pcnr0sLO67unREQahH9dNoCfndCZT5Zs4U/vL2XsEzPYVXKIJWMbIYWGiEgQmjWJ4dYzurHortN58/ohFO4p4/EvV3ldVtgpNEREDoOZ0b9dc0b3a8PTX69m887Ien5DoSEiUgs3n3Y0VVXw0MfLvS4lrBQaIiK10PaoBC4b3J7XZq1n2eYir8sJG4WGiEgtTTipC03jovntpHks3riLl79bx6s56w99YAOmW25FRGqpedNY7juvN7e9voAzH5kKgBlkpSXSv11zj6sLDY00RESOwNl92vDpzSdy2xndeP7qgaQlxXH724uorGocD07vT6EhInKE0pLi+dmJnRmWlcrvz+rBgg07eW9B45yrSqEhIlKHzu7dmpaJsXyyeIvXpYSEQkNEpA75fMawrFS+XrmNqkZ4ikqhISJSx07o2pLCPWUs3LjT61LqnEJDRKSODcvyLwX01fLGtwy1QkNEpI61TIyjZ5tk3pyzgXfmbaSkvNLrkuqMQkNEJATGDmzH+u17ueHlOVz8+HTyi0q9LqlOKDRERELgskHtWXTX6Uy85BiWbSnikidnNIoL4woNEZEQiYnycVaf1tw7pjcrtu5m5ppCr0s6YgoNEZEQG9mrFfExPt6d3/Af+FNoiIiEWNO4aEZ0S+f9BZuoqKzyupwjotAQEQmDc/q2pmBPGd+sKvC6lCOi0BARCYPhR6eRkhDDk1NzvS7liCg0RETCID4migkndWHqim1MW7nN63JqTaEhIhImlw5qT5tm8fz5w6U41zBvv1VoiIiESXxMFDee2pX5eTt5f8Fmr8uplZCGhpmNNLNlZrbSzG49QJuLzGyxmS0ys5f2ey/ZzPLM7NFQ1ikiEi7nHZNJ1/RE/vrRMsob4J1UIVvu1cyigInAqUAeMNPMJjvnFldrkwXcBgx1zm03s7T9PuYe4KtQ1SgiEm5RPuO3p3fjmudyuPjx6XRo0ZT83aWc1rMVlx7XDjPzusSDCuVIYyCw0jmX65wrA14BRu/X5lpgonNuO4Bzbuv3b5jZACAd+CiENYqIhN2I7mn8akQWlVWOGbkF5G3fy/+9tZDfTppf76caCdlIA8gA1lfbzgOO269NVwAzmwZEAXc65z40Mx/wIHApcMqBfoCZjQfGA7Rr167uKhcRCSEz48ZTu3LjqV0BqKpyPPDRMh77YhUjuqczslcrjys8MK8vhEcDWcBwYBzwpJmlANcD7zvn8g52sHPuCedctnMuOzU1NeTFioiEgs9n3HRqVzq0SOCRT1fU6zurQhkaG4C21bYzA/uqywMmO+fKnXOrgeX4Q2QwMMHM1gB/BS43s/tDWKuIiKeio3xMODmLxZt28fbcjV6Xc0ChDI2ZQJaZdTSzWGAsMHm/Nm/hH2VgZi3xn67Kdc79xDnXzjnXAbgZeM45V+PdVyIijcWYfm3omp7Ir/87l2uencnesvq3eFPIQsM5VwFMAKYAS4BXnXOLzOxuMxsVaDYFKDCzxcDnwC3OuYY9MYuISC1FR/l46xdDufm0rnyyZCuPfr7C65J+xOrzubPDkZ2d7XJycrwuQ0SkTvzm1bm8M28jH/xqGF3SkkL2c8xslnMuO9j2Xl8IFxGRGvzuzO4kxEZz06vzKK2oP6epFBoiIvVQy8Q4/nJBH+bl7eSudxYf+oAwUWiIiNRTp/dsxXUndualb9eRU0+WilVoiIjUY78c0YWkuGhe/Had16UACg0RkXotITaac4/J4L0Fm9i+p2zf/pLySp6amsuHCzexaefesNWj0BARqecuOa4dZRVVTJr1v0kyHv50BX98bwnXvTCbq/8TvjtHQzn3lIiI1IFurZIZ1Oko/v7Jck48OhWfGU9NzeW8/hlcPqQDxWUVYatFz2mIiDQAG3fsZdSj0wBHlYOKyio+u3k4LRPjjuhz9ZyGiEgj1CalCU9cPoC0pHiGZbXk6SuPPeLAqA2dnhIRaSCOadec9381zNMaNNIQEZGgKTRERCRoCg0REQmaQkNERIKm0BARkaApNEREJGgKDRERCZpCQ0REgtZophExs3xgrdd11JGWwDavi6iH1C81U7/UTP1Ss/37pb1zLjXYgxtNaDQmZpZzOHPBRAr1S83ULzVTv9TsSPtFp6dERCRoCg0REQmaQqN+esLrAuop9UvN1C81U7/U7Ij6Rdc0REQkaBppiIhI0BQaIiISNIWGiIgETaHRgJjZMDP7l5k9ZWbfeF1PfWFmw81saqBvhntdT31hZt0DfTLJzH7udT31hZl1MrOnzWyS17V4rTZ9odAIEzN7xsy2mtnC/faPNLNlZrbSzG492Gc456Y6564D3gWeDWW94VIX/QI4YDcQD+SFqtZwqqO/L0sCf18uAoaGst5wqaN+yXXOXR3aSr1zOH1Uq75wzukVhhdwAnAMsLDavihgFdAJiAXmAT2A3viDoforrdpxrwJJXn+n+tIvgC9wXDrwotffqb70S+CYUcAHwCVef6f61C+B4yZ5/X287qPa9EV0MMEiR84595WZddhv90BgpXMuF8DMXgFGO+fuA86u6XPMrB2w0zlXFMJyw6au+iVgOxAXijrDra76xTk3GZhsZu8BL4Wu4vCo478vjdLh9BGw+HA/X6envJUBrK+2nRfYdzBXA/8OWUX1w2H1i5mdZ2aPA88Dj4a4Ni8dbr8MN7NHAn3zfqiL89Dh9ksLM/sX0N/Mbgt1cfVEjX1Um77QSKOBcc7d4XUN9Y1z7g3gDa/rqG+cc18AX3hcRr3jnCsArvO6jvqgNn2hkYa3NgBtq21nBvZFOvVLzdQvNVO/HFqd9ZFCw1szgSwz62hmscBYYLLHNdUH6peaqV9qpn45tDrrI4VGmJjZy8B04GgzyzOzq51zFcAEYAqwBHjVObfIyzrDTf1SM/VLzdQvhxbqPtKEhSIiEjSNNEREJGgKDRERCZpCQ0REgqbQEBGRoCk0REQkaAoNEREJmkJDGj0z2x3mnxfWtU7MLMXMrg/nz5TIpdAQOUxmdtA525xzQ8L8M1MAhYaEhUJDIpKZdTazD81sVmDVv26B/eeY2bdmNsfMPjGz9MD+O83seTObBjwf2H7GzL4ws1wz+2W1z94d+O/wwPuTzGypmb1oZhZ478zAvlmBmWjfraHGK81sspl9BnxqZolm9qmZzTazBWY2OtD0fqCzmc01swcCx95iZjPNbL6Z3RXKvpTIolluJVI9AVznnFthZscB/wROBr4GBjnnnJldA/wWuClwTA/geOfcXjO7E+gGnAQkAcvM7DHnXPl+P6c/0BPYCEwDhppZDvA4cIJzbnVg2ocDOQbo45wrDIw2znXO7TKzlsAMM5sM3Ar0cs71AzCz04As/GsoGP71NE5wzn1V694SCVBoSMQxs0RgCPBa4Bd/+N/iTZnAf82sNf4VzlZXO3Syc25vte33nHOlQKmZbcW/cuD+y81+55zLC/zcuUAH/EvT5jrnvv/sl4HxByj3Y+dc4felA38ysxOAKvxrJKTXcMxpgdecwHYi/hBRaMgRU2hIJPIBO77/zXw//wD+5pybbGbDgTurvbdnv7al1f5cSc3/fwqmzcFU/5k/AVKBAc65cjNbg39d9P0ZcJ9z7vHD/Fkih6RrGhJxnHO7gNVmdiGA+fUNvN2M/60zcEWISlgGdKq2JOfFQR7XDNgaCIyTgPaB/UX4T5F9bwpwVWBEhZllmFnaEVctgkYaEhkSzKz6aaO/4f+t/TEz+wMQA7wCzMM/snjNzLYDnwEd67qYwDWR64EPzWwP/rUOgvEi8I6ZLQBygKWBzysws2lmthD4wDl3i5l1B6YHTr/tBi4Fttb1d5HIo6nRRTxgZonOud2Bu6kmAiuccw95XZfIoej0lIg3rg1cGF+E/7STrj9Ig6CRhoiIBE0jDRERCZpCQ0REgqbQEBGRoCk0REQkaAoNEREJmkJDRESC9v8BrYbvfNfILREAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = lr_finder.plot(suggest = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    base_momentum: 0.85\n",
       "    dampening: 0\n",
       "    initial_lr: 0.0008\n",
       "    lr: 0.019999999517965248\n",
       "    max_lr: 0.02\n",
       "    max_momentum: 0.9\n",
       "    min_lr: 8e-06\n",
       "    momentum: 0.8500000012055691\n",
       "    nesterov: False\n",
       "    weight_decay: 5e-05\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.max_lr = 2e-2\n",
    "model.current_epoch = 0\n",
    "model.configure_optimizers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "    | Name                                                               | Type                    | Params\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "0   | loss_func                                                          | BCELoss                 | 0     \n",
      "1   | encoder                                                            | ResNetModel             | 11 M  \n",
      "2   | encoder.encoder                                                    | Sequential              | 11 M  \n",
      "3   | encoder.encoder.0                                                  | Conv2d                  | 9 K   \n",
      "4   | encoder.encoder.1                                                  | BatchNorm2d             | 128   \n",
      "5   | encoder.encoder.2                                                  | ReLU                    | 0     \n",
      "6   | encoder.encoder.3                                                  | MaxPool2d               | 0     \n",
      "7   | encoder.encoder.4                                                  | Sequential              | 147 K \n",
      "8   | encoder.encoder.4.0                                                | BasicBlock              | 73 K  \n",
      "9   | encoder.encoder.4.0.conv1                                          | Conv2d                  | 36 K  \n",
      "10  | encoder.encoder.4.0.bn1                                            | BatchNorm2d             | 128   \n",
      "11  | encoder.encoder.4.0.relu                                           | ReLU                    | 0     \n",
      "12  | encoder.encoder.4.0.conv2                                          | Conv2d                  | 36 K  \n",
      "13  | encoder.encoder.4.0.bn2                                            | BatchNorm2d             | 128   \n",
      "14  | encoder.encoder.4.1                                                | BasicBlock              | 73 K  \n",
      "15  | encoder.encoder.4.1.conv1                                          | Conv2d                  | 36 K  \n",
      "16  | encoder.encoder.4.1.bn1                                            | BatchNorm2d             | 128   \n",
      "17  | encoder.encoder.4.1.relu                                           | ReLU                    | 0     \n",
      "18  | encoder.encoder.4.1.conv2                                          | Conv2d                  | 36 K  \n",
      "19  | encoder.encoder.4.1.bn2                                            | BatchNorm2d             | 128   \n",
      "20  | encoder.encoder.5                                                  | Sequential              | 525 K \n",
      "21  | encoder.encoder.5.0                                                | BasicBlock              | 230 K \n",
      "22  | encoder.encoder.5.0.conv1                                          | Conv2d                  | 73 K  \n",
      "23  | encoder.encoder.5.0.bn1                                            | BatchNorm2d             | 256   \n",
      "24  | encoder.encoder.5.0.relu                                           | ReLU                    | 0     \n",
      "25  | encoder.encoder.5.0.conv2                                          | Conv2d                  | 147 K \n",
      "26  | encoder.encoder.5.0.bn2                                            | BatchNorm2d             | 256   \n",
      "27  | encoder.encoder.5.0.downsample                                     | Sequential              | 8 K   \n",
      "28  | encoder.encoder.5.0.downsample.0                                   | Conv2d                  | 8 K   \n",
      "29  | encoder.encoder.5.0.downsample.1                                   | BatchNorm2d             | 256   \n",
      "30  | encoder.encoder.5.1                                                | BasicBlock              | 295 K \n",
      "31  | encoder.encoder.5.1.conv1                                          | Conv2d                  | 147 K \n",
      "32  | encoder.encoder.5.1.bn1                                            | BatchNorm2d             | 256   \n",
      "33  | encoder.encoder.5.1.relu                                           | ReLU                    | 0     \n",
      "34  | encoder.encoder.5.1.conv2                                          | Conv2d                  | 147 K \n",
      "35  | encoder.encoder.5.1.bn2                                            | BatchNorm2d             | 256   \n",
      "36  | encoder.encoder.6                                                  | Sequential              | 2 M   \n",
      "37  | encoder.encoder.6.0                                                | BasicBlock              | 919 K \n",
      "38  | encoder.encoder.6.0.conv1                                          | Conv2d                  | 294 K \n",
      "39  | encoder.encoder.6.0.bn1                                            | BatchNorm2d             | 512   \n",
      "40  | encoder.encoder.6.0.relu                                           | ReLU                    | 0     \n",
      "41  | encoder.encoder.6.0.conv2                                          | Conv2d                  | 589 K \n",
      "42  | encoder.encoder.6.0.bn2                                            | BatchNorm2d             | 512   \n",
      "43  | encoder.encoder.6.0.downsample                                     | Sequential              | 33 K  \n",
      "44  | encoder.encoder.6.0.downsample.0                                   | Conv2d                  | 32 K  \n",
      "45  | encoder.encoder.6.0.downsample.1                                   | BatchNorm2d             | 512   \n",
      "46  | encoder.encoder.6.1                                                | BasicBlock              | 1 M   \n",
      "47  | encoder.encoder.6.1.conv1                                          | Conv2d                  | 589 K \n",
      "48  | encoder.encoder.6.1.bn1                                            | BatchNorm2d             | 512   \n",
      "49  | encoder.encoder.6.1.relu                                           | ReLU                    | 0     \n",
      "50  | encoder.encoder.6.1.conv2                                          | Conv2d                  | 589 K \n",
      "51  | encoder.encoder.6.1.bn2                                            | BatchNorm2d             | 512   \n",
      "52  | encoder.encoder.7                                                  | Sequential              | 8 M   \n",
      "53  | encoder.encoder.7.0                                                | BasicBlock              | 3 M   \n",
      "54  | encoder.encoder.7.0.conv1                                          | Conv2d                  | 1 M   \n",
      "55  | encoder.encoder.7.0.bn1                                            | BatchNorm2d             | 1 K   \n",
      "56  | encoder.encoder.7.0.relu                                           | ReLU                    | 0     \n",
      "57  | encoder.encoder.7.0.conv2                                          | Conv2d                  | 2 M   \n",
      "58  | encoder.encoder.7.0.bn2                                            | BatchNorm2d             | 1 K   \n",
      "59  | encoder.encoder.7.0.downsample                                     | Sequential              | 132 K \n",
      "60  | encoder.encoder.7.0.downsample.0                                   | Conv2d                  | 131 K \n",
      "61  | encoder.encoder.7.0.downsample.1                                   | BatchNorm2d             | 1 K   \n",
      "62  | encoder.encoder.7.1                                                | BasicBlock              | 4 M   \n",
      "63  | encoder.encoder.7.1.conv1                                          | Conv2d                  | 2 M   \n",
      "64  | encoder.encoder.7.1.bn1                                            | BatchNorm2d             | 1 K   \n",
      "65  | encoder.encoder.7.1.relu                                           | ReLU                    | 0     \n",
      "66  | encoder.encoder.7.1.conv2                                          | Conv2d                  | 2 M   \n",
      "67  | encoder.encoder.7.1.bn2                                            | BatchNorm2d             | 1 K   \n",
      "68  | transformers                                                       | TransformerProjectLayer | 13 M  \n",
      "69  | transformers.downsample                                            | Conv2d                  | 262 K \n",
      "70  | transformers.activation                                            | Mish                    | 0     \n",
      "71  | transformers.bn                                                    | BatchNorm2d             | 1 K   \n",
      "72  | transformers.transformers                                          | Transformers            | 12 M  \n",
      "73  | transformers.transformers.position_encoding                        | PositionEmbedding       | 18 K  \n",
      "74  | transformers.transformers.position_encoding.embed                  | Embedding               | 18 K  \n",
      "75  | transformers.transformers.encoder                                  | TransformersBlock       | 12 M  \n",
      "76  | transformers.transformers.encoder.layers                           | ModuleList              | 12 M  \n",
      "77  | transformers.transformers.encoder.layers.0                         | TransformerLayer        | 2 M   \n",
      "78  | transformers.transformers.encoder.layers.0.self_attention          | MultiheadAttention      | 1 M   \n",
      "79  | transformers.transformers.encoder.layers.0.self_attention.out_proj | Linear                  | 262 K \n",
      "80  | transformers.transformers.encoder.layers.0.linear1                 | Linear                  | 525 K \n",
      "81  | transformers.transformers.encoder.layers.0.linear2                 | Linear                  | 524 K \n",
      "82  | transformers.transformers.encoder.layers.0.norm1                   | LayerNorm               | 1 K   \n",
      "83  | transformers.transformers.encoder.layers.0.norm2                   | LayerNorm               | 1 K   \n",
      "84  | transformers.transformers.encoder.layers.0.dropout                 | Dropout                 | 0     \n",
      "85  | transformers.transformers.encoder.layers.0.activation              | ReLU                    | 0     \n",
      "86  | transformers.transformers.encoder.layers.1                         | TransformerLayer        | 2 M   \n",
      "87  | transformers.transformers.encoder.layers.1.self_attention          | MultiheadAttention      | 1 M   \n",
      "88  | transformers.transformers.encoder.layers.1.self_attention.out_proj | Linear                  | 262 K \n",
      "89  | transformers.transformers.encoder.layers.1.linear1                 | Linear                  | 525 K \n",
      "90  | transformers.transformers.encoder.layers.1.linear2                 | Linear                  | 524 K \n",
      "91  | transformers.transformers.encoder.layers.1.norm1                   | LayerNorm               | 1 K   \n",
      "92  | transformers.transformers.encoder.layers.1.norm2                   | LayerNorm               | 1 K   \n",
      "93  | transformers.transformers.encoder.layers.1.dropout                 | Dropout                 | 0     \n",
      "94  | transformers.transformers.encoder.layers.1.activation              | ReLU                    | 0     \n",
      "95  | transformers.transformers.encoder.layers.2                         | TransformerLayer        | 2 M   \n",
      "96  | transformers.transformers.encoder.layers.2.self_attention          | MultiheadAttention      | 1 M   \n",
      "97  | transformers.transformers.encoder.layers.2.self_attention.out_proj | Linear                  | 262 K \n",
      "98  | transformers.transformers.encoder.layers.2.linear1                 | Linear                  | 525 K \n",
      "99  | transformers.transformers.encoder.layers.2.linear2                 | Linear                  | 524 K \n",
      "100 | transformers.transformers.encoder.layers.2.norm1                   | LayerNorm               | 1 K   \n",
      "101 | transformers.transformers.encoder.layers.2.norm2                   | LayerNorm               | 1 K   \n",
      "102 | transformers.transformers.encoder.layers.2.dropout                 | Dropout                 | 0     \n",
      "103 | transformers.transformers.encoder.layers.2.activation              | ReLU                    | 0     \n",
      "104 | transformers.transformers.encoder.layers.3                         | TransformerLayer        | 2 M   \n",
      "105 | transformers.transformers.encoder.layers.3.self_attention          | MultiheadAttention      | 1 M   \n",
      "106 | transformers.transformers.encoder.layers.3.self_attention.out_proj | Linear                  | 262 K \n",
      "107 | transformers.transformers.encoder.layers.3.linear1                 | Linear                  | 525 K \n",
      "108 | transformers.transformers.encoder.layers.3.linear2                 | Linear                  | 524 K \n",
      "109 | transformers.transformers.encoder.layers.3.norm1                   | LayerNorm               | 1 K   \n",
      "110 | transformers.transformers.encoder.layers.3.norm2                   | LayerNorm               | 1 K   \n",
      "111 | transformers.transformers.encoder.layers.3.dropout                 | Dropout                 | 0     \n",
      "112 | transformers.transformers.encoder.layers.3.activation              | ReLU                    | 0     \n",
      "113 | transformers.transformers.encoder.layers.4                         | TransformerLayer        | 2 M   \n",
      "114 | transformers.transformers.encoder.layers.4.self_attention          | MultiheadAttention      | 1 M   \n",
      "115 | transformers.transformers.encoder.layers.4.self_attention.out_proj | Linear                  | 262 K \n",
      "116 | transformers.transformers.encoder.layers.4.linear1                 | Linear                  | 525 K \n",
      "117 | transformers.transformers.encoder.layers.4.linear2                 | Linear                  | 524 K \n",
      "118 | transformers.transformers.encoder.layers.4.norm1                   | LayerNorm               | 1 K   \n",
      "119 | transformers.transformers.encoder.layers.4.norm2                   | LayerNorm               | 1 K   \n",
      "120 | transformers.transformers.encoder.layers.4.dropout                 | Dropout                 | 0     \n",
      "121 | transformers.transformers.encoder.layers.4.activation              | ReLU                    | 0     \n",
      "122 | transformers.transformers.encoder.layers.5                         | TransformerLayer        | 2 M   \n",
      "123 | transformers.transformers.encoder.layers.5.self_attention          | MultiheadAttention      | 1 M   \n",
      "124 | transformers.transformers.encoder.layers.5.self_attention.out_proj | Linear                  | 262 K \n",
      "125 | transformers.transformers.encoder.layers.5.linear1                 | Linear                  | 525 K \n",
      "126 | transformers.transformers.encoder.layers.5.linear2                 | Linear                  | 524 K \n",
      "127 | transformers.transformers.encoder.layers.5.norm1                   | LayerNorm               | 1 K   \n",
      "128 | transformers.transformers.encoder.layers.5.norm2                   | LayerNorm               | 1 K   \n",
      "129 | transformers.transformers.encoder.layers.5.dropout                 | Dropout                 | 0     \n",
      "130 | transformers.transformers.encoder.layers.5.activation              | ReLU                    | 0     \n",
      "131 | transformers.head                                                  | Sequential              | 262 K \n",
      "132 | transformers.head.0                                                | Linear                  | 262 K \n",
      "133 | transformers.head.1                                                | Mish                    | 0     \n",
      "134 | transformers.head.2                                                | BatchNorm1d             | 72    \n",
      "135 | transformers.head.3                                                | Dropout                 | 0     \n",
      "136 | transformers.learned_mean                                          | Sequential              | 513   \n",
      "137 | transformers.learned_mean.0                                        | Linear                  | 513   \n",
      "138 | transformers.learned_mean.1                                        | Flatten                 | 0     \n",
      "139 | transformers.learned_mean.2                                        | Softmax                 | 0     \n",
      "140 | transformers.prob_layer                                            | Linear                  | 2 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21833447cd48412db18ee2ad8cd0ff9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
