{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GeForce GTX 1080 Ti', ('10.92', 'gigabytes'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "\n",
    "def format_bytes(size):\n",
    "    # 2**10 = 1024\n",
    "    power = 2**10\n",
    "    n = 0\n",
    "    power_labels = {0 : '', 1: 'kilo', 2: 'mega', 3: 'giga', 4: 'tera'}\n",
    "    while size > power:\n",
    "        size /= power\n",
    "        n += 1\n",
    "    return \"%.2f\" % size, power_labels[n] + 'bytes'\n",
    "\n",
    "torch.cuda.get_device_name(), format_bytes(torch.cuda.get_device_properties(device).total_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.dataset import load_supervised_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Load from data frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/kientiet/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n"
     ]
    }
   ],
   "source": [
    "from trainer.supervised.baseline import BaselineTrainer\n",
    "model = BaselineTrainer()\n",
    "max_epoches = model.get_max_epoches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kientiet/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: Checkpoint directory /home/kientiet/Documents/My Project/python/panda-kaggle/checkpoint/baseline/resnet50_32x4d exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/kientiet/Documents/My Project/python/panda-kaggle/checkpoint/baseline/resnet50_32x4d'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = os.path.join(os.getcwd(), \"checkpoint\", model.model_name)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath = checkpoint_path,\n",
    "    save_top_k = 5,\n",
    "    verbose = True,\n",
    "    monitor = 'kappa_score',\n",
    "    mode = 'max'\n",
    ")\n",
    "\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "tb_logger = loggers.TensorBoardLogger('logs/', name = model.model_name)\n",
    "trainer = pl.Trainer(checkpoint_callback = checkpoint_callback,\n",
    "                    nb_sanity_val_steps = 0, \n",
    "                    max_epochs = max_epoches, \n",
    "                    gpus = -1, \n",
    "                    logger = tb_logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "    | Name                             | Type              | Params\n",
      "-------------------------------------------------------------------\n",
      "0   | loss_func                        | BCELoss           | 0     \n",
      "1   | encoder                          | ResNetModel       | 22 M  \n",
      "2   | encoder.encoder                  | Sequential        | 22 M  \n",
      "3   | encoder.encoder.0                | Conv2d            | 9 K   \n",
      "4   | encoder.encoder.1                | BatchNorm2d       | 128   \n",
      "5   | encoder.encoder.2                | ReLU              | 0     \n",
      "6   | encoder.encoder.3                | MaxPool2d         | 0     \n",
      "7   | encoder.encoder.4                | Sequential        | 205 K \n",
      "8   | encoder.encoder.4.0              | Bottleneck        | 63 K  \n",
      "9   | encoder.encoder.4.0.conv1        | Conv2d            | 8 K   \n",
      "10  | encoder.encoder.4.0.bn1          | BatchNorm2d       | 256   \n",
      "11  | encoder.encoder.4.0.conv2        | Conv2d            | 4 K   \n",
      "12  | encoder.encoder.4.0.bn2          | BatchNorm2d       | 256   \n",
      "13  | encoder.encoder.4.0.conv3        | Conv2d            | 32 K  \n",
      "14  | encoder.encoder.4.0.bn3          | BatchNorm2d       | 512   \n",
      "15  | encoder.encoder.4.0.relu         | ReLU              | 0     \n",
      "16  | encoder.encoder.4.0.downsample   | Sequential        | 16 K  \n",
      "17  | encoder.encoder.4.0.downsample.0 | Conv2d            | 16 K  \n",
      "18  | encoder.encoder.4.0.downsample.1 | BatchNorm2d       | 512   \n",
      "19  | encoder.encoder.4.1              | Bottleneck        | 71 K  \n",
      "20  | encoder.encoder.4.1.conv1        | Conv2d            | 32 K  \n",
      "21  | encoder.encoder.4.1.bn1          | BatchNorm2d       | 256   \n",
      "22  | encoder.encoder.4.1.conv2        | Conv2d            | 4 K   \n",
      "23  | encoder.encoder.4.1.bn2          | BatchNorm2d       | 256   \n",
      "24  | encoder.encoder.4.1.conv3        | Conv2d            | 32 K  \n",
      "25  | encoder.encoder.4.1.bn3          | BatchNorm2d       | 512   \n",
      "26  | encoder.encoder.4.1.relu         | ReLU              | 0     \n",
      "27  | encoder.encoder.4.2              | Bottleneck        | 71 K  \n",
      "28  | encoder.encoder.4.2.conv1        | Conv2d            | 32 K  \n",
      "29  | encoder.encoder.4.2.bn1          | BatchNorm2d       | 256   \n",
      "30  | encoder.encoder.4.2.conv2        | Conv2d            | 4 K   \n",
      "31  | encoder.encoder.4.2.bn2          | BatchNorm2d       | 256   \n",
      "32  | encoder.encoder.4.2.conv3        | Conv2d            | 32 K  \n",
      "33  | encoder.encoder.4.2.bn3          | BatchNorm2d       | 512   \n",
      "34  | encoder.encoder.4.2.relu         | ReLU              | 0     \n",
      "35  | encoder.encoder.5                | Sequential        | 1 M   \n",
      "36  | encoder.encoder.5.0              | Bottleneck        | 349 K \n",
      "37  | encoder.encoder.5.0.conv1        | Conv2d            | 65 K  \n",
      "38  | encoder.encoder.5.0.bn1          | BatchNorm2d       | 512   \n",
      "39  | encoder.encoder.5.0.conv2        | Conv2d            | 18 K  \n",
      "40  | encoder.encoder.5.0.bn2          | BatchNorm2d       | 512   \n",
      "41  | encoder.encoder.5.0.conv3        | Conv2d            | 131 K \n",
      "42  | encoder.encoder.5.0.bn3          | BatchNorm2d       | 1 K   \n",
      "43  | encoder.encoder.5.0.relu         | ReLU              | 0     \n",
      "44  | encoder.encoder.5.0.downsample   | Sequential        | 132 K \n",
      "45  | encoder.encoder.5.0.downsample.0 | Conv2d            | 131 K \n",
      "46  | encoder.encoder.5.0.downsample.1 | BatchNorm2d       | 1 K   \n",
      "47  | encoder.encoder.5.1              | Bottleneck        | 282 K \n",
      "48  | encoder.encoder.5.1.conv1        | Conv2d            | 131 K \n",
      "49  | encoder.encoder.5.1.bn1          | BatchNorm2d       | 512   \n",
      "50  | encoder.encoder.5.1.conv2        | Conv2d            | 18 K  \n",
      "51  | encoder.encoder.5.1.bn2          | BatchNorm2d       | 512   \n",
      "52  | encoder.encoder.5.1.conv3        | Conv2d            | 131 K \n",
      "53  | encoder.encoder.5.1.bn3          | BatchNorm2d       | 1 K   \n",
      "54  | encoder.encoder.5.1.relu         | ReLU              | 0     \n",
      "55  | encoder.encoder.5.2              | Bottleneck        | 282 K \n",
      "56  | encoder.encoder.5.2.conv1        | Conv2d            | 131 K \n",
      "57  | encoder.encoder.5.2.bn1          | BatchNorm2d       | 512   \n",
      "58  | encoder.encoder.5.2.conv2        | Conv2d            | 18 K  \n",
      "59  | encoder.encoder.5.2.bn2          | BatchNorm2d       | 512   \n",
      "60  | encoder.encoder.5.2.conv3        | Conv2d            | 131 K \n",
      "61  | encoder.encoder.5.2.bn3          | BatchNorm2d       | 1 K   \n",
      "62  | encoder.encoder.5.2.relu         | ReLU              | 0     \n",
      "63  | encoder.encoder.5.3              | Bottleneck        | 282 K \n",
      "64  | encoder.encoder.5.3.conv1        | Conv2d            | 131 K \n",
      "65  | encoder.encoder.5.3.bn1          | BatchNorm2d       | 512   \n",
      "66  | encoder.encoder.5.3.conv2        | Conv2d            | 18 K  \n",
      "67  | encoder.encoder.5.3.bn2          | BatchNorm2d       | 512   \n",
      "68  | encoder.encoder.5.3.conv3        | Conv2d            | 131 K \n",
      "69  | encoder.encoder.5.3.bn3          | BatchNorm2d       | 1 K   \n",
      "70  | encoder.encoder.5.3.relu         | ReLU              | 0     \n",
      "71  | encoder.encoder.6                | Sequential        | 7 M   \n",
      "72  | encoder.encoder.6.0              | Bottleneck        | 1 M   \n",
      "73  | encoder.encoder.6.0.conv1        | Conv2d            | 262 K \n",
      "74  | encoder.encoder.6.0.bn1          | BatchNorm2d       | 1 K   \n",
      "75  | encoder.encoder.6.0.conv2        | Conv2d            | 73 K  \n",
      "76  | encoder.encoder.6.0.bn2          | BatchNorm2d       | 1 K   \n",
      "77  | encoder.encoder.6.0.conv3        | Conv2d            | 524 K \n",
      "78  | encoder.encoder.6.0.bn3          | BatchNorm2d       | 2 K   \n",
      "79  | encoder.encoder.6.0.relu         | ReLU              | 0     \n",
      "80  | encoder.encoder.6.0.downsample   | Sequential        | 526 K \n",
      "81  | encoder.encoder.6.0.downsample.0 | Conv2d            | 524 K \n",
      "82  | encoder.encoder.6.0.downsample.1 | BatchNorm2d       | 2 K   \n",
      "83  | encoder.encoder.6.1              | Bottleneck        | 1 M   \n",
      "84  | encoder.encoder.6.1.conv1        | Conv2d            | 524 K \n",
      "85  | encoder.encoder.6.1.bn1          | BatchNorm2d       | 1 K   \n",
      "86  | encoder.encoder.6.1.conv2        | Conv2d            | 73 K  \n",
      "87  | encoder.encoder.6.1.bn2          | BatchNorm2d       | 1 K   \n",
      "88  | encoder.encoder.6.1.conv3        | Conv2d            | 524 K \n",
      "89  | encoder.encoder.6.1.bn3          | BatchNorm2d       | 2 K   \n",
      "90  | encoder.encoder.6.1.relu         | ReLU              | 0     \n",
      "91  | encoder.encoder.6.2              | Bottleneck        | 1 M   \n",
      "92  | encoder.encoder.6.2.conv1        | Conv2d            | 524 K \n",
      "93  | encoder.encoder.6.2.bn1          | BatchNorm2d       | 1 K   \n",
      "94  | encoder.encoder.6.2.conv2        | Conv2d            | 73 K  \n",
      "95  | encoder.encoder.6.2.bn2          | BatchNorm2d       | 1 K   \n",
      "96  | encoder.encoder.6.2.conv3        | Conv2d            | 524 K \n",
      "97  | encoder.encoder.6.2.bn3          | BatchNorm2d       | 2 K   \n",
      "98  | encoder.encoder.6.2.relu         | ReLU              | 0     \n",
      "99  | encoder.encoder.6.3              | Bottleneck        | 1 M   \n",
      "100 | encoder.encoder.6.3.conv1        | Conv2d            | 524 K \n",
      "101 | encoder.encoder.6.3.bn1          | BatchNorm2d       | 1 K   \n",
      "102 | encoder.encoder.6.3.conv2        | Conv2d            | 73 K  \n",
      "103 | encoder.encoder.6.3.bn2          | BatchNorm2d       | 1 K   \n",
      "104 | encoder.encoder.6.3.conv3        | Conv2d            | 524 K \n",
      "105 | encoder.encoder.6.3.bn3          | BatchNorm2d       | 2 K   \n",
      "106 | encoder.encoder.6.3.relu         | ReLU              | 0     \n",
      "107 | encoder.encoder.6.4              | Bottleneck        | 1 M   \n",
      "108 | encoder.encoder.6.4.conv1        | Conv2d            | 524 K \n",
      "109 | encoder.encoder.6.4.bn1          | BatchNorm2d       | 1 K   \n",
      "110 | encoder.encoder.6.4.conv2        | Conv2d            | 73 K  \n",
      "111 | encoder.encoder.6.4.bn2          | BatchNorm2d       | 1 K   \n",
      "112 | encoder.encoder.6.4.conv3        | Conv2d            | 524 K \n",
      "113 | encoder.encoder.6.4.bn3          | BatchNorm2d       | 2 K   \n",
      "114 | encoder.encoder.6.4.relu         | ReLU              | 0     \n",
      "115 | encoder.encoder.6.5              | Bottleneck        | 1 M   \n",
      "116 | encoder.encoder.6.5.conv1        | Conv2d            | 524 K \n",
      "117 | encoder.encoder.6.5.bn1          | BatchNorm2d       | 1 K   \n",
      "118 | encoder.encoder.6.5.conv2        | Conv2d            | 73 K  \n",
      "119 | encoder.encoder.6.5.bn2          | BatchNorm2d       | 1 K   \n",
      "120 | encoder.encoder.6.5.conv3        | Conv2d            | 524 K \n",
      "121 | encoder.encoder.6.5.bn3          | BatchNorm2d       | 2 K   \n",
      "122 | encoder.encoder.6.5.relu         | ReLU              | 0     \n",
      "123 | encoder.encoder.7                | Sequential        | 14 M  \n",
      "124 | encoder.encoder.7.0              | Bottleneck        | 5 M   \n",
      "125 | encoder.encoder.7.0.conv1        | Conv2d            | 1 M   \n",
      "126 | encoder.encoder.7.0.bn1          | BatchNorm2d       | 2 K   \n",
      "127 | encoder.encoder.7.0.conv2        | Conv2d            | 294 K \n",
      "128 | encoder.encoder.7.0.bn2          | BatchNorm2d       | 2 K   \n",
      "129 | encoder.encoder.7.0.conv3        | Conv2d            | 2 M   \n",
      "130 | encoder.encoder.7.0.bn3          | BatchNorm2d       | 4 K   \n",
      "131 | encoder.encoder.7.0.relu         | ReLU              | 0     \n",
      "132 | encoder.encoder.7.0.downsample   | Sequential        | 2 M   \n",
      "133 | encoder.encoder.7.0.downsample.0 | Conv2d            | 2 M   \n",
      "134 | encoder.encoder.7.0.downsample.1 | BatchNorm2d       | 4 K   \n",
      "135 | encoder.encoder.7.1              | Bottleneck        | 4 M   \n",
      "136 | encoder.encoder.7.1.conv1        | Conv2d            | 2 M   \n",
      "137 | encoder.encoder.7.1.bn1          | BatchNorm2d       | 2 K   \n",
      "138 | encoder.encoder.7.1.conv2        | Conv2d            | 294 K \n",
      "139 | encoder.encoder.7.1.bn2          | BatchNorm2d       | 2 K   \n",
      "140 | encoder.encoder.7.1.conv3        | Conv2d            | 2 M   \n",
      "141 | encoder.encoder.7.1.bn3          | BatchNorm2d       | 4 K   \n",
      "142 | encoder.encoder.7.1.relu         | ReLU              | 0     \n",
      "143 | encoder.encoder.7.2              | Bottleneck        | 4 M   \n",
      "144 | encoder.encoder.7.2.conv1        | Conv2d            | 2 M   \n",
      "145 | encoder.encoder.7.2.bn1          | BatchNorm2d       | 2 K   \n",
      "146 | encoder.encoder.7.2.conv2        | Conv2d            | 294 K \n",
      "147 | encoder.encoder.7.2.bn2          | BatchNorm2d       | 2 K   \n",
      "148 | encoder.encoder.7.2.conv3        | Conv2d            | 2 M   \n",
      "149 | encoder.encoder.7.2.bn3          | BatchNorm2d       | 4 K   \n",
      "150 | encoder.encoder.7.2.relu         | ReLU              | 0     \n",
      "151 | project_layer                    | ProjectLayer      | 2 M   \n",
      "152 | project_layer.avg_pooling        | AdaptiveAvgPool2d | 0     \n",
      "153 | project_layer.max_pooling        | AdaptiveMaxPool2d | 0     \n",
      "154 | project_layer.head               | Sequential        | 2 M   \n",
      "155 | project_layer.head.0             | Flatten           | 0     \n",
      "156 | project_layer.head.1             | Linear            | 2 M   \n",
      "157 | project_layer.head.2             | Mish              | 0     \n",
      "158 | project_layer.head.3             | BatchNorm1d       | 1 K   \n",
      "159 | project_layer.head.4             | Dropout           | 0     \n",
      "160 | project_layer.head.5             | Linear            | 2 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb82ee68aa740bbbf4642dfcb82ccdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', max=200.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/kientiet/Documents/My Project/python/panda-kaggle/trainer/supervised/baseline.py(28)forward()\n",
      "-> batch_size, image_batch, channels, height, width = images.shape\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/kientiet/Documents/My Project/python/panda-kaggle/trainer/supervised/baseline.py(29)forward()\n",
      "-> images = images.reshape(-1, channels, height, width)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/kientiet/Documents/My Project/python/panda-kaggle/trainer/supervised/baseline.py(32)forward()\n",
      "-> logits = self.encoder(images)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/kientiet/Documents/My Project/python/panda-kaggle/trainer/supervised/baseline.py(33)forward()\n",
      "-> shape = logits.shape\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/kientiet/Documents/My Project/python/panda-kaggle/trainer/supervised/baseline.py(35)forward()\n",
      "-> logits = logits.view(-1, image_batch, shape[1], shape[2], shape[3]).permute(0, 2, 1, 3, 4).contiguous() \\\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/kientiet/Documents/My Project/python/panda-kaggle/trainer/supervised/baseline.py(36)forward()\n",
      "-> .view(-1, shape[1], shape[2] * image_batch, shape[3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/kientiet/Documents/My Project/python/panda-kaggle/trainer/supervised/baseline.py(35)forward()\n",
      "-> logits = logits.view(-1, image_batch, shape[1], shape[2], shape[3]).permute(0, 2, 1, 3, 4).contiguous() \\\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/kientiet/Documents/My Project/python/panda-kaggle/trainer/supervised/baseline.py(37)forward()\n",
      "-> logits = self.project_layer(logits)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/kientiet/Documents/My Project/python/panda-kaggle/trainer/supervised/baseline.py(38)forward()\n",
      "-> logits = torch.sigmoid(logits)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  logits.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5da4ffd3fec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr_finder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/lr_finder.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(self, model, train_dataloader, min_lr, max_lr, num_training, mode, num_accumulation_steps)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# Fit, lr & loss logged in callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# Prompt if we stopped early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tpu\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no-cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/distrib_parts.py\u001b[0m in \u001b[0;36msingle_gpu_train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpu_core_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0;31m# RUN TNG EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;31m# update LR schedulers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;31m# RUN TRAIN STEP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;31m# ---------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0m_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m             \u001b[0mbatch_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_step_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m                 \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;31m# check if loss or model weights are nan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    558\u001b[0m                                                                     opt_idx, self.hiddens)\n\u001b[1;32m    559\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m                             \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                         \u001b[0;31m# format and reduce outputs accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_forward\u001b[0;34m(self, batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransfer_batch_to_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;31m# TPU support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/My Project/python/panda-kaggle/trainer/supervised/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, train_batch, batch_idx)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"learning_rate\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"log\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/My Project/python/panda-kaggle/trainer/supervised/baseline.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/My Project/python/panda-kaggle/trainer/supervised/baseline.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_finder = trainer.lr_find(model, min_lr = 1e-8, max_lr = 5., num_training = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = lr_finder.plot(suggest = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    base_momentum: 0.85\n",
       "    dampening: 0\n",
       "    initial_lr: 8e-05\n",
       "    lr: 0.001999998892022334\n",
       "    max_lr: 0.002\n",
       "    max_momentum: 0.9\n",
       "    min_lr: 8.000000000000001e-07\n",
       "    momentum: 0.8500000277105259\n",
       "    nesterov: False\n",
       "    weight_decay: 5e-05\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.max_lr = 2e-3\n",
    "model.current_epoch = 0\n",
    "model.configure_optimizers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "    | Name                             | Type              | Params\n",
      "-------------------------------------------------------------------\n",
      "0   | loss_func                        | CrossEntropyLoss  | 0     \n",
      "1   | encoder                          | ResNetModel       | 22 M  \n",
      "2   | encoder.encoder                  | Sequential        | 22 M  \n",
      "3   | encoder.encoder.0                | Conv2d            | 9 K   \n",
      "4   | encoder.encoder.1                | BatchNorm2d       | 128   \n",
      "5   | encoder.encoder.2                | ReLU              | 0     \n",
      "6   | encoder.encoder.3                | MaxPool2d         | 0     \n",
      "7   | encoder.encoder.4                | Sequential        | 205 K \n",
      "8   | encoder.encoder.4.0              | Bottleneck        | 63 K  \n",
      "9   | encoder.encoder.4.0.conv1        | Conv2d            | 8 K   \n",
      "10  | encoder.encoder.4.0.bn1          | BatchNorm2d       | 256   \n",
      "11  | encoder.encoder.4.0.conv2        | Conv2d            | 4 K   \n",
      "12  | encoder.encoder.4.0.bn2          | BatchNorm2d       | 256   \n",
      "13  | encoder.encoder.4.0.conv3        | Conv2d            | 32 K  \n",
      "14  | encoder.encoder.4.0.bn3          | BatchNorm2d       | 512   \n",
      "15  | encoder.encoder.4.0.relu         | ReLU              | 0     \n",
      "16  | encoder.encoder.4.0.downsample   | Sequential        | 16 K  \n",
      "17  | encoder.encoder.4.0.downsample.0 | Conv2d            | 16 K  \n",
      "18  | encoder.encoder.4.0.downsample.1 | BatchNorm2d       | 512   \n",
      "19  | encoder.encoder.4.1              | Bottleneck        | 71 K  \n",
      "20  | encoder.encoder.4.1.conv1        | Conv2d            | 32 K  \n",
      "21  | encoder.encoder.4.1.bn1          | BatchNorm2d       | 256   \n",
      "22  | encoder.encoder.4.1.conv2        | Conv2d            | 4 K   \n",
      "23  | encoder.encoder.4.1.bn2          | BatchNorm2d       | 256   \n",
      "24  | encoder.encoder.4.1.conv3        | Conv2d            | 32 K  \n",
      "25  | encoder.encoder.4.1.bn3          | BatchNorm2d       | 512   \n",
      "26  | encoder.encoder.4.1.relu         | ReLU              | 0     \n",
      "27  | encoder.encoder.4.2              | Bottleneck        | 71 K  \n",
      "28  | encoder.encoder.4.2.conv1        | Conv2d            | 32 K  \n",
      "29  | encoder.encoder.4.2.bn1          | BatchNorm2d       | 256   \n",
      "30  | encoder.encoder.4.2.conv2        | Conv2d            | 4 K   \n",
      "31  | encoder.encoder.4.2.bn2          | BatchNorm2d       | 256   \n",
      "32  | encoder.encoder.4.2.conv3        | Conv2d            | 32 K  \n",
      "33  | encoder.encoder.4.2.bn3          | BatchNorm2d       | 512   \n",
      "34  | encoder.encoder.4.2.relu         | ReLU              | 0     \n",
      "35  | encoder.encoder.5                | Sequential        | 1 M   \n",
      "36  | encoder.encoder.5.0              | Bottleneck        | 349 K \n",
      "37  | encoder.encoder.5.0.conv1        | Conv2d            | 65 K  \n",
      "38  | encoder.encoder.5.0.bn1          | BatchNorm2d       | 512   \n",
      "39  | encoder.encoder.5.0.conv2        | Conv2d            | 18 K  \n",
      "40  | encoder.encoder.5.0.bn2          | BatchNorm2d       | 512   \n",
      "41  | encoder.encoder.5.0.conv3        | Conv2d            | 131 K \n",
      "42  | encoder.encoder.5.0.bn3          | BatchNorm2d       | 1 K   \n",
      "43  | encoder.encoder.5.0.relu         | ReLU              | 0     \n",
      "44  | encoder.encoder.5.0.downsample   | Sequential        | 132 K \n",
      "45  | encoder.encoder.5.0.downsample.0 | Conv2d            | 131 K \n",
      "46  | encoder.encoder.5.0.downsample.1 | BatchNorm2d       | 1 K   \n",
      "47  | encoder.encoder.5.1              | Bottleneck        | 282 K \n",
      "48  | encoder.encoder.5.1.conv1        | Conv2d            | 131 K \n",
      "49  | encoder.encoder.5.1.bn1          | BatchNorm2d       | 512   \n",
      "50  | encoder.encoder.5.1.conv2        | Conv2d            | 18 K  \n",
      "51  | encoder.encoder.5.1.bn2          | BatchNorm2d       | 512   \n",
      "52  | encoder.encoder.5.1.conv3        | Conv2d            | 131 K \n",
      "53  | encoder.encoder.5.1.bn3          | BatchNorm2d       | 1 K   \n",
      "54  | encoder.encoder.5.1.relu         | ReLU              | 0     \n",
      "55  | encoder.encoder.5.2              | Bottleneck        | 282 K \n",
      "56  | encoder.encoder.5.2.conv1        | Conv2d            | 131 K \n",
      "57  | encoder.encoder.5.2.bn1          | BatchNorm2d       | 512   \n",
      "58  | encoder.encoder.5.2.conv2        | Conv2d            | 18 K  \n",
      "59  | encoder.encoder.5.2.bn2          | BatchNorm2d       | 512   \n",
      "60  | encoder.encoder.5.2.conv3        | Conv2d            | 131 K \n",
      "61  | encoder.encoder.5.2.bn3          | BatchNorm2d       | 1 K   \n",
      "62  | encoder.encoder.5.2.relu         | ReLU              | 0     \n",
      "63  | encoder.encoder.5.3              | Bottleneck        | 282 K \n",
      "64  | encoder.encoder.5.3.conv1        | Conv2d            | 131 K \n",
      "65  | encoder.encoder.5.3.bn1          | BatchNorm2d       | 512   \n",
      "66  | encoder.encoder.5.3.conv2        | Conv2d            | 18 K  \n",
      "67  | encoder.encoder.5.3.bn2          | BatchNorm2d       | 512   \n",
      "68  | encoder.encoder.5.3.conv3        | Conv2d            | 131 K \n",
      "69  | encoder.encoder.5.3.bn3          | BatchNorm2d       | 1 K   \n",
      "70  | encoder.encoder.5.3.relu         | ReLU              | 0     \n",
      "71  | encoder.encoder.6                | Sequential        | 7 M   \n",
      "72  | encoder.encoder.6.0              | Bottleneck        | 1 M   \n",
      "73  | encoder.encoder.6.0.conv1        | Conv2d            | 262 K \n",
      "74  | encoder.encoder.6.0.bn1          | BatchNorm2d       | 1 K   \n",
      "75  | encoder.encoder.6.0.conv2        | Conv2d            | 73 K  \n",
      "76  | encoder.encoder.6.0.bn2          | BatchNorm2d       | 1 K   \n",
      "77  | encoder.encoder.6.0.conv3        | Conv2d            | 524 K \n",
      "78  | encoder.encoder.6.0.bn3          | BatchNorm2d       | 2 K   \n",
      "79  | encoder.encoder.6.0.relu         | ReLU              | 0     \n",
      "80  | encoder.encoder.6.0.downsample   | Sequential        | 526 K \n",
      "81  | encoder.encoder.6.0.downsample.0 | Conv2d            | 524 K \n",
      "82  | encoder.encoder.6.0.downsample.1 | BatchNorm2d       | 2 K   \n",
      "83  | encoder.encoder.6.1              | Bottleneck        | 1 M   \n",
      "84  | encoder.encoder.6.1.conv1        | Conv2d            | 524 K \n",
      "85  | encoder.encoder.6.1.bn1          | BatchNorm2d       | 1 K   \n",
      "86  | encoder.encoder.6.1.conv2        | Conv2d            | 73 K  \n",
      "87  | encoder.encoder.6.1.bn2          | BatchNorm2d       | 1 K   \n",
      "88  | encoder.encoder.6.1.conv3        | Conv2d            | 524 K \n",
      "89  | encoder.encoder.6.1.bn3          | BatchNorm2d       | 2 K   \n",
      "90  | encoder.encoder.6.1.relu         | ReLU              | 0     \n",
      "91  | encoder.encoder.6.2              | Bottleneck        | 1 M   \n",
      "92  | encoder.encoder.6.2.conv1        | Conv2d            | 524 K \n",
      "93  | encoder.encoder.6.2.bn1          | BatchNorm2d       | 1 K   \n",
      "94  | encoder.encoder.6.2.conv2        | Conv2d            | 73 K  \n",
      "95  | encoder.encoder.6.2.bn2          | BatchNorm2d       | 1 K   \n",
      "96  | encoder.encoder.6.2.conv3        | Conv2d            | 524 K \n",
      "97  | encoder.encoder.6.2.bn3          | BatchNorm2d       | 2 K   \n",
      "98  | encoder.encoder.6.2.relu         | ReLU              | 0     \n",
      "99  | encoder.encoder.6.3              | Bottleneck        | 1 M   \n",
      "100 | encoder.encoder.6.3.conv1        | Conv2d            | 524 K \n",
      "101 | encoder.encoder.6.3.bn1          | BatchNorm2d       | 1 K   \n",
      "102 | encoder.encoder.6.3.conv2        | Conv2d            | 73 K  \n",
      "103 | encoder.encoder.6.3.bn2          | BatchNorm2d       | 1 K   \n",
      "104 | encoder.encoder.6.3.conv3        | Conv2d            | 524 K \n",
      "105 | encoder.encoder.6.3.bn3          | BatchNorm2d       | 2 K   \n",
      "106 | encoder.encoder.6.3.relu         | ReLU              | 0     \n",
      "107 | encoder.encoder.6.4              | Bottleneck        | 1 M   \n",
      "108 | encoder.encoder.6.4.conv1        | Conv2d            | 524 K \n",
      "109 | encoder.encoder.6.4.bn1          | BatchNorm2d       | 1 K   \n",
      "110 | encoder.encoder.6.4.conv2        | Conv2d            | 73 K  \n",
      "111 | encoder.encoder.6.4.bn2          | BatchNorm2d       | 1 K   \n",
      "112 | encoder.encoder.6.4.conv3        | Conv2d            | 524 K \n",
      "113 | encoder.encoder.6.4.bn3          | BatchNorm2d       | 2 K   \n",
      "114 | encoder.encoder.6.4.relu         | ReLU              | 0     \n",
      "115 | encoder.encoder.6.5              | Bottleneck        | 1 M   \n",
      "116 | encoder.encoder.6.5.conv1        | Conv2d            | 524 K \n",
      "117 | encoder.encoder.6.5.bn1          | BatchNorm2d       | 1 K   \n",
      "118 | encoder.encoder.6.5.conv2        | Conv2d            | 73 K  \n",
      "119 | encoder.encoder.6.5.bn2          | BatchNorm2d       | 1 K   \n",
      "120 | encoder.encoder.6.5.conv3        | Conv2d            | 524 K \n",
      "121 | encoder.encoder.6.5.bn3          | BatchNorm2d       | 2 K   \n",
      "122 | encoder.encoder.6.5.relu         | ReLU              | 0     \n",
      "123 | encoder.encoder.7                | Sequential        | 14 M  \n",
      "124 | encoder.encoder.7.0              | Bottleneck        | 5 M   \n",
      "125 | encoder.encoder.7.0.conv1        | Conv2d            | 1 M   \n",
      "126 | encoder.encoder.7.0.bn1          | BatchNorm2d       | 2 K   \n",
      "127 | encoder.encoder.7.0.conv2        | Conv2d            | 294 K \n",
      "128 | encoder.encoder.7.0.bn2          | BatchNorm2d       | 2 K   \n",
      "129 | encoder.encoder.7.0.conv3        | Conv2d            | 2 M   \n",
      "130 | encoder.encoder.7.0.bn3          | BatchNorm2d       | 4 K   \n",
      "131 | encoder.encoder.7.0.relu         | ReLU              | 0     \n",
      "132 | encoder.encoder.7.0.downsample   | Sequential        | 2 M   \n",
      "133 | encoder.encoder.7.0.downsample.0 | Conv2d            | 2 M   \n",
      "134 | encoder.encoder.7.0.downsample.1 | BatchNorm2d       | 4 K   \n",
      "135 | encoder.encoder.7.1              | Bottleneck        | 4 M   \n",
      "136 | encoder.encoder.7.1.conv1        | Conv2d            | 2 M   \n",
      "137 | encoder.encoder.7.1.bn1          | BatchNorm2d       | 2 K   \n",
      "138 | encoder.encoder.7.1.conv2        | Conv2d            | 294 K \n",
      "139 | encoder.encoder.7.1.bn2          | BatchNorm2d       | 2 K   \n",
      "140 | encoder.encoder.7.1.conv3        | Conv2d            | 2 M   \n",
      "141 | encoder.encoder.7.1.bn3          | BatchNorm2d       | 4 K   \n",
      "142 | encoder.encoder.7.1.relu         | ReLU              | 0     \n",
      "143 | encoder.encoder.7.2              | Bottleneck        | 4 M   \n",
      "144 | encoder.encoder.7.2.conv1        | Conv2d            | 2 M   \n",
      "145 | encoder.encoder.7.2.bn1          | BatchNorm2d       | 2 K   \n",
      "146 | encoder.encoder.7.2.conv2        | Conv2d            | 294 K \n",
      "147 | encoder.encoder.7.2.bn2          | BatchNorm2d       | 2 K   \n",
      "148 | encoder.encoder.7.2.conv3        | Conv2d            | 2 M   \n",
      "149 | encoder.encoder.7.2.bn3          | BatchNorm2d       | 4 K   \n",
      "150 | encoder.encoder.7.2.relu         | ReLU              | 0     \n",
      "151 | project_layer                    | ProjectLayer      | 2 M   \n",
      "152 | project_layer.avg_pooling        | AdaptiveAvgPool2d | 0     \n",
      "153 | project_layer.max_pooling        | AdaptiveMaxPool2d | 0     \n",
      "154 | project_layer.head               | Sequential        | 2 M   \n",
      "155 | project_layer.head.0             | Flatten           | 0     \n",
      "156 | project_layer.head.1             | Linear            | 2 M   \n",
      "157 | project_layer.head.2             | Mish              | 0     \n",
      "158 | project_layer.head.3             | BatchNorm1d       | 1 K   \n",
      "159 | project_layer.head.4             | Dropout           | 0     \n",
      "160 | project_layer.head.5             | Linear            | 3 K   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Return trainloader\n",
      ">> Return valloader\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09fe6752fec540d9be9a8ecef0cd76c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
